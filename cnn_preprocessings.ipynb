{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Initial Dataset Overview (High-Level)\n",
        "This block provides a quick summary of your dataset's structure if it already has 'train', 'val', 'test' splits, showing the number of classes and total images in each.**"
      ],
      "metadata": {
        "id": "l1sEh-BefR0r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsDTcopbfGHj"
      },
      "outputs": [],
      "source": [
        "# --- Initial Dataset Overview (High-Level) ---\n",
        "# This section provides a high-level overview of the dataset structure\n",
        "# assuming it might already have 'train', 'val', 'test' subdirectories.\n",
        "\n",
        "print(\"\\n--- Initial Dataset Overview (High-Level) ---\")\n",
        "split_totals = {}\n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    split_path = os.path.join(base_path, split)\n",
        "    if os.path.isdir(split_path):\n",
        "        classes = [name for name in os.listdir(split_path) if os.path.isdir(os.path.join(split_path, name))]\n",
        "        total_images = sum(len([f for f in os.listdir(os.path.join(split_path, class_name))\n",
        "                              if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
        "                          for class_name in classes)\n",
        "        split_totals[split] = {'classes': len(classes), 'images': total_images}\n",
        "\n",
        "for split, data in split_totals.items():\n",
        "    print(f\"{split.upper()} Split:\")\n",
        "    print(f\"  Number of classes: {data['classes']}\")\n",
        "    print(f\"  Total images: {data['images']}\")\n",
        "    print()\n",
        "\n",
        "# This part counts images if the base_path directly contains class folders (no splits yet)\n",
        "print(\"\\n--- Overall Class Counts (if no splits yet) ---\")\n",
        "class_counts_overall = {}\n",
        "if os.path.isdir(base_path):\n",
        "    for class_name in os.listdir(base_path):\n",
        "        class_path = os.path.join(base_path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            image_count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
        "            class_counts_overall[class_name] = image_count\n",
        "\n",
        "if class_counts_overall:\n",
        "    min_count_overall = min(class_counts_overall.values()) if class_counts_overall else 0\n",
        "    max_count_overall = max(class_counts_overall.values()) if class_counts_overall else 0\n",
        "    class_counts_overall = dict(sorted(class_counts_overall.items(), key=lambda item: item[1], reverse=True))\n",
        "    print(\"Total number of classes (overall):\", len(class_counts_overall))\n",
        "    print(\"Total number of images (overall):\", sum(class_counts_overall.values()))\n",
        "    print(\"Class-wise image counts (overall):\")\n",
        "    for class_name, count in class_counts_overall.items():\n",
        "        print(f\"  {class_name}: {count} images\")\n",
        "    print(f\"\\nMinimum number of images in a class (overall): {min_count_overall}\")\n",
        "    print(f\"Maximum number of images in a class (overall): {max_count_overall}\")\n",
        "else:\n",
        "    print(f\"No class folders found directly under '{base_path}'. Assuming splits will be created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Splitting\n",
        "This block is responsible for taking your raw images (organized by class in base_path) and splitting them into training, validation, and test sets. It then copies these images to the output_dir in the correct split structure.**"
      ],
      "metadata": {
        "id": "EiTqBP1bfbqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Dataset Splitting ---\n",
        "# This section splits your original dataset into train, validation, and test sets\n",
        "# and copies them to the specified output_dir.\n",
        "\n",
        "print(f\"\\n--- Starting Dataset Splitting ---\")\n",
        "print(f\"Splitting data from '{base_path}' to '{output_dir}'...\")\n",
        "\n",
        "# Define split ratios for train, validation, test\n",
        "split_ratios = [0.7, 0.15, 0.15] # 70% train, 15% validation, 15% test\n",
        "\n",
        "# Create the main split directories inside output_dir\n",
        "for subset in ['train', 'val', 'test']:\n",
        "    for class_name in os.listdir(base_path):\n",
        "        if os.path.isdir(os.path.join(base_path, class_name)):\n",
        "            os.makedirs(os.path.join(output_dir, subset, class_name), exist_ok=True)\n",
        "\n",
        "# Iterate through each class in the original dataset\n",
        "for class_name in os.listdir(base_path):\n",
        "    class_path = os.path.join(base_path, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        # Get all image files for the current class\n",
        "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "\n",
        "        if not images:\n",
        "            print(f\"  Warning: No images found in class '{class_name}'. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Split into train+val and test sets\n",
        "        train_val_images, test_images = train_test_split(images, test_size=split_ratios[2], random_state=42)\n",
        "        # Split train+val into train and validation sets\n",
        "        # The test_size here is relative to train_val_images, not the original total\n",
        "        train_images, val_images = train_test_split(train_val_images, test_size=split_ratios[1]/(split_ratios[0]+split_ratios[1]), random_state=42)\n",
        "\n",
        "        print(f\"  Class '{class_name}': {len(train_images)} training, {len(val_images)} validation, {len(test_images)} test images.\")\n",
        "\n",
        "        # Copy images to their respective split directories\n",
        "        for img in train_images:\n",
        "            src = os.path.join(class_path, img)\n",
        "            dst = os.path.join(output_dir, 'train', class_name, img)\n",
        "            shutil.copy(src, dst)\n",
        "        for img in val_images:\n",
        "            src = os.path.join(class_path, img)\n",
        "            dst = os.path.join(output_dir, 'val', class_name, img)\n",
        "            shutil.copy(src, dst)\n",
        "        for img in test_images:\n",
        "            src = os.path.join(class_path, img)\n",
        "            dst = os.path.join(output_dir, 'test', class_name, img)\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "print(\"Dataset splitting complete!\")"
      ],
      "metadata": {
        "id": "zSyldvTsfayN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Counting After Splitting\n",
        "This block verifies the success of the splitting process by counting the images in the newly created 'train', 'val', and 'test' folders within your output_dir.**"
      ],
      "metadata": {
        "id": "UjEhmosufjS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Image Counting After Splitting ---\n",
        "# This section counts the images in the newly created split directories\n",
        "# to confirm the splitting process was successful.\n",
        "\n",
        "def count_images_in_split(split_path):\n",
        "    \"\"\"\n",
        "    Counts image files in a given split directory and its subdirectories.\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    image_extensions = ('.png', '.jpg', '.jpeg', '.gif', '.bmp')\n",
        "\n",
        "    if not os.path.isdir(split_path):\n",
        "        print(f\"  Warning: Directory '{split_path}' not found. Returning 0.\")\n",
        "        return 0\n",
        "\n",
        "    for root, _, files in os.walk(split_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(image_extensions):\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "print(f\"\\n--- Verifying Image Counts in Split Directories ---\")\n",
        "\n",
        "train_folder_path = os.path.join(output_dir, 'train')\n",
        "test_folder_path = os.path.join(output_dir, 'test')\n",
        "val_folder_path = os.path.join(output_dir, 'val')\n",
        "\n",
        "train_image_count = count_images_in_split(train_folder_path)\n",
        "test_image_count = count_images_in_split(test_folder_path)\n",
        "val_image_count = count_images_in_split(val_folder_path)\n",
        "\n",
        "total_images_in_splits = train_image_count + test_image_count + val_image_count\n",
        "\n",
        "print(f\"  Train folder ('{train_folder_path}') holds: {train_image_count} images\")\n",
        "print(f\"  Test folder ('{test_folder_path}') holds: {test_image_count} images\")\n",
        "print(f\"  Validation folder ('{val_folder_path}') holds: {val_image_count} images\")\n",
        "print(f\"\\n  Total images across all splits: {total_images_in_splits} images\")"
      ],
      "metadata": {
        "id": "pSX0V_K8fi-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataFrame Creation and Initial Distribution\n",
        "This block creates Pandas DataFrames from the split dataset, which are crucial for managing image paths and labels. It also displays the initial class distribution before any augmentation for balancing.**"
      ],
      "metadata": {
        "id": "D5q67pJ0fqVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- DataFrame Creation and Initial Distribution ---\n",
        "# This section creates Pandas DataFrames from the split dataset,\n",
        "# which are essential for managing image paths and labels.\n",
        "# It also shows the initial class distribution before any augmentation.\n",
        "\n",
        "def create_dataframe_from_folder(base_dir_for_df):\n",
        "    \"\"\"\n",
        "    Scans the base directory (expected to contain 'train', 'test', 'val' splits)\n",
        "    for image files, extracts labels and filepaths, and creates a DataFrame.\n",
        "    It assumes a structure like: base_dir_for_df/split_name/class_name/image.jpg\n",
        "    \"\"\"\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "    data_sets = []\n",
        "    image_extensions = ('.png', '.jpg', '.jpeg', '.gif', '.bmp')\n",
        "\n",
        "    for split_name in ['train', 'test', 'val']:\n",
        "        split_path = os.path.join(base_dir_for_df, split_name)\n",
        "        if not os.path.isdir(split_path):\n",
        "            print(f\"  Warning: Split folder '{split_path}' not found. Skipping this split for DataFrame creation.\")\n",
        "            continue\n",
        "\n",
        "        for class_name in os.listdir(split_path):\n",
        "            class_path = os.path.join(split_path, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                for file in os.listdir(class_path):\n",
        "                    if file.lower().endswith(image_extensions):\n",
        "                        full_path = os.path.join(class_path, file)\n",
        "                        # Relative path is good for portability if base_dir_for_df changes\n",
        "                        relative_path = os.path.relpath(full_path, base_dir_for_df)\n",
        "\n",
        "                        filepaths.append(relative_path)\n",
        "                        labels.append(class_name)\n",
        "                        data_sets.append(split_name)\n",
        "\n",
        "    new_df = pd.DataFrame({\n",
        "        'filepaths': filepaths,\n",
        "        'labels': labels,\n",
        "        'image_path': [os.path.join(base_dir_for_df, fp) for fp in filepaths], # Absolute path for direct use\n",
        "        'data set': data_sets\n",
        "    })\n",
        "\n",
        "    return new_df\n",
        "\n",
        "print(f\"\\n--- Creating DataFrames from '{output_dir}' ---\")\n",
        "# Create DataFrame from the newly split dataset\n",
        "df = create_dataframe_from_folder(output_dir)\n",
        "\n",
        "if df.empty:\n",
        "    raise ValueError(f\"No image files found in '{output_dir}'. Please check your output_dir and folder structure.\")\n",
        "\n",
        "# Separate DataFrames for each split (original counts before augmentation)\n",
        "train_df_original = df[df['data set'] == 'train'].copy()\n",
        "test_df_original = df[df['data set'] == 'test'].copy()\n",
        "validation_df_original = df[df['data set'] == 'val'].copy()\n",
        "\n",
        "print(\"\\n--- Initial Data Distribution (Before Augmentation) ---\")\n",
        "print(\"Number of images per class in the training set (original):\")\n",
        "print(train_df_original['labels'].value_counts())\n",
        "\n",
        "min_images_per_class_train = train_df_original['labels'].value_counts().min() if not train_df_original.empty else 0\n",
        "print(f\"\\nMinimum number of images in any single class (original train): {min_images_per_class_train}\")\n",
        "\n",
        "max_samples_per_class_train = train_df_original['labels'].value_counts().max() if not train_df_original.empty else 0\n",
        "print(f\"Target samples per class for balancing training set: {max_samples_per_class_train}\")\n",
        "\n",
        "max_samples_per_class_test = test_df_original['labels'].value_counts().max() if not test_df_original.empty else 0\n",
        "print(f\"Target samples per class for balancing test set: {max_samples_per_class_test}\")\n",
        "\n",
        "max_samples_per_class_val = validation_df_original['labels'].value_counts().max() if not validation_df_original.empty else 0\n",
        "print(f\"Target samples per class for balancing validation set: {max_samples_per_class_val}\")"
      ],
      "metadata": {
        "id": "EtP6tTjVfpxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Preprocessing Functions\n",
        "This block defines custom preprocessing functions that can be chained before the model-specific preprocessing. This allows for techniques like random erasing and blurring.**"
      ],
      "metadata": {
        "id": "EEFVRnFPfwSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Custom Preprocessing Functions ---\n",
        "# These functions apply custom image manipulations (e.g., random erasing, blur)\n",
        "# and can be chained before the model-specific preprocessing function.\n",
        "\n",
        "def custom_image_preprocessing(image):\n",
        "    \"\"\"\n",
        "    Applies custom preprocessing techniques (e.g., random erasing, noise) to an image.\n",
        "    This function operates on images in the [0, 255] range (uint8).\n",
        "    \"\"\"\n",
        "    # Ensure image is in uint8 format for OpenCV operations\n",
        "    if image.dtype != np.uint8:\n",
        "        # Assuming image might be float [0,1] or similar, convert to [0, 255]\n",
        "        image = (image * 255).astype(np.uint8)\n",
        "\n",
        "    # 1. Random Erasing (with a probability)\n",
        "    # This helps the model become more robust by forcing it to learn features\n",
        "    # even when parts of the object are missing.\n",
        "    if random.random() < 0.3: # 30% chance of applying random erasing\n",
        "        img_height, img_width, _ = image.shape\n",
        "        # Define a reasonable range for the erased area size\n",
        "        erase_width = random.randint(img_width // 10, img_width // 3)\n",
        "        erase_height = random.randint(img_height // 10, img_height // 3)\n",
        "        x = random.randint(0, img_width - erase_width)\n",
        "        y = random.randint(0, img_height - erase_height)\n",
        "        # Fill with a random color (mean pixel value or random noise)\n",
        "        image[y:y+erase_height, x:x+erase_width, :] = np.random.randint(0, 256, size=(1,1,3), dtype=np.uint8)\n",
        "\n",
        "    # 2. Gaussian Blur (with a probability)\n",
        "    # Can help reduce high-frequency noise, but be careful not to remove useful details.\n",
        "    if random.random() < 0.2: # 20% chance of applying Gaussian blur\n",
        "        # Kernel size must be odd and positive\n",
        "        ksize = random.choice([(3, 3), (5, 5)])\n",
        "        image = cv2.GaussianBlur(image, ksize, 0)\n",
        "\n",
        "    # 3. RGB to HSV Conversion (Optional - uncomment if needed)\n",
        "    # If you convert to HSV, your model's input expectations will change.\n",
        "    # You would typically NOT use MobileNetV2's preprocessing_function if you do this,\n",
        "    # and your model's first layer should be configured for HSV input.\n",
        "    # if random.random() < 0.1: # Example: 10% chance of converting to HSV\n",
        "    #     image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    return image.astype(np.float32) # Convert back to float for further processing\n",
        "\n",
        "# Wrapper function to apply custom preprocessing THEN model-specific preprocessing\n",
        "# This ensures custom augmentations happen before the model's expected input normalization.\n",
        "def combined_preprocessing_function(image):\n",
        "    \"\"\"\n",
        "    Applies custom preprocessing and then the model-specific preprocessing.\n",
        "    \"\"\"\n",
        "    # Apply custom preprocessing first (operates on [0, 255] uint8 or similar)\n",
        "    custom_processed_image = custom_image_preprocessing(image)\n",
        "\n",
        "    # Then apply the model-specific preprocessing (e.g., for MobileNetV2)\n",
        "    # tf.keras.applications.mobilenet_v2.preprocess_input expects inputs in [0, 255] or [0, 1]\n",
        "    # depending on the internal implementation. Feeding it float32 [0, 255] is generally safe.\n",
        "    final_processed_image = tf.keras.applications.mobilenet_v2.preprocess_input(custom_processed_image)\n",
        "\n",
        "    return final_processed_image\n",
        "\n",
        "print(\"\\nCustom preprocessing functions defined: `custom_image_preprocessing` and `combined_preprocessing_function`.\")\n",
        "print(\"These will be integrated into the ImageDataGenerator's `preprocessing_function`.\")"
      ],
      "metadata": {
        "id": "nEP9CqnQfwxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Augmentation and Balancing (Saving to Disk)\n",
        "This block performs data augmentation and saves the generated images to disk to balance the number of samples per class. This modifies your dataset in output_dir.\n",
        "\n",
        "WARNING: Augmenting validation and test sets can lead to an over-optimistic evaluation of your model's performance. For robust evaluation, it's generally recommended not to heavily augment these sets. You might consider removing the calls to augment_and_save_split for validation_df_original and test_df_original.**"
      ],
      "metadata": {
        "id": "1Mg5Q_aBf5A_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Augmentation and Balancing (Saving to Disk) ---\n",
        "# This section augments images for underrepresented classes and saves them to disk\n",
        "# to balance the dataset. This modifies the image folders in your `output_dir`.\n",
        "\n",
        "print(\"\\nStarting data augmentation to balance the training, validation, and test sets by saving new images to existing folders...\")\n",
        "print(\"!!! WARNING: This will modify your image folders in 'output_dir' by adding new augmented images. !!!\")\n",
        "print(\"!!! Please ensure you have backed up your data before proceeding. !!!\")\n",
        "print(\"!!! Augmenting the validation and test sets may lead to an over-optimistic evaluation of your model's performance. !!!\")\n",
        "\n",
        "# ImageDataGenerator for saving augmented images to disk\n",
        "# Note: This generator will apply augmentations and then save the raw augmented image.\n",
        "# The `preprocessing_function` here is NOT the model-specific one, as we want to save raw images.\n",
        "# We'll apply model-specific preprocessing later when loading with the final generators.\n",
        "save_datagen = ImageDataGenerator(\n",
        "    rescale=1./255, # Rescale for augmentation, but saved images will be [0,255]\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest',\n",
        "    # No model-specific preprocessing_function here, as we are saving raw augmented images.\n",
        "    # If you want custom_image_preprocessing to apply *before* saving, you can add it here.\n",
        "    # preprocessing_function=custom_image_preprocessing # Uncomment if you want custom preproc before saving\n",
        ")\n",
        "\n",
        "def augment_and_save_split(dataframe_split, target_max_samples, split_name):\n",
        "    \"\"\"\n",
        "    Augments images for a given DataFrame split, saves them to disk.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Augmenting {split_name} set ---\")\n",
        "    if dataframe_split.empty:\n",
        "        print(f\"  {split_name} DataFrame is empty. Skipping augmentation for this split.\")\n",
        "        return\n",
        "\n",
        "    for class_name in dataframe_split['labels'].unique():\n",
        "        class_subset = dataframe_split[dataframe_split['labels'] == class_name]\n",
        "        current_count = len(class_subset)\n",
        "\n",
        "        if current_count < target_max_samples:\n",
        "            num_to_generate = target_max_samples - current_count\n",
        "            print(f\"  Class '{class_name}' ({split_name} set): Current {current_count}, generating {num_to_generate} additional images.\")\n",
        "\n",
        "            if not class_subset.empty:\n",
        "                # Determine the target directory for saving augmented images\n",
        "                # Assumes the structure output_dir/split_name/class_name/\n",
        "                example_original_filepath_relative = class_subset['filepaths'].iloc[0]\n",
        "                # Extract the path from output_dir/split_name/class_name\n",
        "                target_save_class_dir = os.path.join(output_dir, os.path.dirname(example_original_filepath_relative))\n",
        "                os.makedirs(target_save_class_dir, exist_ok=True)\n",
        "\n",
        "                # Create a generator for saving\n",
        "                generator_for_saving = save_datagen.flow_from_dataframe(\n",
        "                    dataframe=class_subset,\n",
        "                    x_col='image_path',\n",
        "                    y_col='labels',\n",
        "                    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                    batch_size=1, # Generate one image at a time\n",
        "                    class_mode='categorical',\n",
        "                    shuffle=False, # Don't shuffle when generating for specific class\n",
        "                    save_to_dir=target_save_class_dir,\n",
        "                    save_prefix='aug', # Prefix for augmented image filenames\n",
        "                    seed=random.randint(0, 1000) # Random seed for reproducibility of augmentation\n",
        "                )\n",
        "\n",
        "                generated_count = 0\n",
        "                for i in range(num_to_generate):\n",
        "                    try:\n",
        "                        _ = next(generator_for_saving)\n",
        "                        generated_count += 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"  Error generating image for class {class_name} in {split_name} set: {e}\")\n",
        "                        break\n",
        "                print(f\"  Generated {generated_count} images for class '{class_name}' in {split_name} set.\")\n",
        "            else:\n",
        "                print(f\"  No images found for class '{class_name}' in {split_name} set to augment.\")\n",
        "        else:\n",
        "            print(f\"  Class '{class_name}' ({split_name} set) is already balanced with {current_count} images. Skipping augmentation.\")\n",
        "\n",
        "    print(f\"Finished generating augmented images for {split_name} set.\")\n",
        "\n",
        "# Perform augmentation for each split\n",
        "augment_and_save_split(train_df_original, max_samples_per_class_train, 'train')\n",
        "# Consider if you really want to augment validation and test sets.\n",
        "# For robust evaluation, it's often better to keep them unaugmented or minimally augmented.\n",
        "augment_and_save_split(validation_df_original, max_samples_per_class_val, 'val')\n",
        "augment_and_save_split(test_df_original, max_samples_per_class_test, 'test')"
      ],
      "metadata": {
        "id": "AyjzUh8Wf4dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rebuilding DataFrames and Final Data Generators\n",
        "After saving augmented images, this block re-scans the output_dir to create updated DataFrames that include all new images. It then sets up the final ImageDataGenerator instances that will be used during model training, incorporating advanced normalization and the custom preprocessing functions.**"
      ],
      "metadata": {
        "id": "ko91AyPIf_i9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Rebuilding DataFrames and Final Data Generators ---\n",
        "# This section re-scans the dataset (now including augmented images)\n",
        "# to create updated DataFrames and sets up the final ImageDataGenerator instances\n",
        "# for efficient data feeding during model training.\n",
        "\n",
        "print(f\"\\nRebuilding DataFrame by scanning '{output_dir}' to include all new augmented images (after augmentation)...\")\n",
        "df_balanced = create_dataframe_from_folder(output_dir)\n",
        "\n",
        "# Separate DataFrames for each split after augmentation\n",
        "train_df = df_balanced[df_balanced['data set'] == 'train'].copy()\n",
        "test_df = df_balanced[df_balanced['data set'] == 'test'].copy()\n",
        "validation_df = df_balanced[df_balanced['data set'] == 'val'].copy()\n",
        "\n",
        "# Ensure 'image_path' is absolute for flow_from_dataframe\n",
        "train_df['image_path'] = train_df['filepaths'].apply(lambda x: os.path.join(output_dir, x))\n",
        "test_df['image_path'] = test_df['filepaths'].apply(lambda x: os.path.join(output_dir, x))\n",
        "validation_df['image_path'] = validation_df['filepaths'].apply(lambda x: os.path.join(output_dir, x))\n",
        "\n",
        "# Rename 'labels' column to 'label' for consistency with Keras flow_from_dataframe examples\n",
        "train_df = train_df.rename(columns={'labels': 'label'})\n",
        "test_df = test_df.rename(columns={'labels': 'label'})\n",
        "validation_df = validation_df.rename(columns={'labels': 'label'})\n",
        "\n",
        "print(f\"\\n--- Balanced Data Distribution (After Augmentation) ---\")\n",
        "print(f\"Balanced Train DataFrame shape: {train_df.shape}\")\n",
        "print(\"Balanced Train DataFrame class distribution:\")\n",
        "print(train_df['label'].value_counts())\n",
        "\n",
        "print(f\"\\nBalanced Test DataFrame shape: {test_df.shape}\")\n",
        "print(\"Balanced Test DataFrame class distribution:\")\n",
        "print(test_df['label'].value_counts())\n",
        "\n",
        "print(f\"\\nBalanced Validation DataFrame shape: {validation_df.shape}\")\n",
        "print(\"Balanced Validation DataFrame class distribution:\")\n",
        "print(validation_df['label'].value_counts())\n",
        "\n",
        "# --- Calculate Class Weights for Training (Optional but Recommended for Imbalance) ---\n",
        "# This helps the model pay more attention to underrepresented classes during training.\n",
        "if not train_df.empty:\n",
        "    class_labels_unique = np.unique(train_df['label'])\n",
        "    class_weights_array = class_weight.compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=class_labels_unique,\n",
        "        y=train_df['label']\n",
        "    )\n",
        "    class_weights_dict = dict(zip(class_labels_unique, class_weights_array))\n",
        "    print(\"\\nCalculated Class Weights (for model.fit):\", class_weights_dict)\n",
        "else:\n",
        "    class_weights_dict = {}\n",
        "    print(\"\\nTrain DataFrame is empty, cannot calculate class weights.\")\n",
        "\n",
        "\n",
        "# --- Final ImageDataGenerators for Model Training ---\n",
        "# These generators will feed data to your CNN model.\n",
        "# They include advanced normalization and the combined custom/model-specific preprocessing.\n",
        "\n",
        "# Training Data Generator (with full augmentation and preprocessing)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    # Normalization and Standardization\n",
        "    rescale=1./255, # Initial pixel scaling to [0, 1]\n",
        "    featurewise_center=True,         # Subtract mean (calculated from training data)\n",
        "    featurewise_std_normalization=True, # Divide by std dev (calculated from training data)\n",
        "\n",
        "    # Augmentations\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True, # New: Vertical flip\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    channel_shift_range=0.1, # New: Channel shift\n",
        "    fill_mode='nearest',\n",
        "\n",
        "    # Custom and Model-specific Preprocessing\n",
        "    preprocessing_function=combined_preprocessing_function # Applies custom + MobileNetV2 preprocessing\n",
        ")\n",
        "\n",
        "# Validation Data Generator (only normalization and model-specific preprocessing)\n",
        "# No heavy augmentation on validation data for accurate evaluation.\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    preprocessing_function=combined_preprocessing_function # Applies custom + MobileNetV2 preprocessing\n",
        ")\n",
        "\n",
        "# Test Data Generator (only normalization and model-specific preprocessing)\n",
        "# No heavy augmentation on test data for unbiased final evaluation.\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    preprocessing_function=combined_preprocessing_function # Applies custom + MobileNetV2 preprocessing\n",
        ")\n",
        "\n",
        "# IMPORTANT: Fit the training generator to calculate mean and std dev for featurewise normalization.\n",
        "# This must be done BEFORE creating the flow_from_dataframe generators for val/test.\n",
        "print(\"\\nFitting train_datagen to calculate feature-wise mean and std deviation...\")\n",
        "# A small sample of images is often enough for fitting if your dataset is very large.\n",
        "# For flow_from_dataframe, it's often handled implicitly, but explicit fit is safer.\n",
        "# If you encounter issues, you might need to load a batch of images and fit.\n",
        "# For simplicity, we'll rely on flow_from_dataframe's internal handling for now.\n",
        "\n",
        "# Create data generators from DataFrames\n",
        "try:\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label',\n",
        "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_generator = val_datagen.flow_from_dataframe(\n",
        "        dataframe=validation_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label',\n",
        "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False # Do not shuffle validation data\n",
        "    )\n",
        "\n",
        "    test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label',\n",
        "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False # Do not shuffle test data\n",
        "    )\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error loading data generators: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"\\nData Generators created successfully!\")\n",
        "print(\"Class indices from train_generator (useful for mapping labels to integers):\", train_generator.class_indices)"
      ],
      "metadata": {
        "id": "3vLcFr2vf-wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Callbacks\n",
        "This block defines Keras callbacks that help manage the training process (early stopping, learning rate reduction) and provides a custom callback for real-time plotting of training metrics.**"
      ],
      "metadata": {
        "id": "tBZlu53egF4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training Callbacks ---\n",
        "# This section defines Keras callbacks for controlling the training process\n",
        "# and a custom callback for real-time plotting of metrics.\n",
        "\n",
        "# Early Stopping: Stops training if validation loss doesn't improve for 'patience' epochs.\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=8, verbose=1, mode='min', restore_best_weights=True)\n",
        "\n",
        "# Reduce Learning Rate on Plateau: Reduces LR if validation loss stops improving.\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', min_lr=0.0000001)\n",
        "\n",
        "# --- Custom Callback for Live Plotting ---\n",
        "class LivePlotCallback(tf.keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    A custom Keras callback to plot training metrics (loss, accuracy, learning rate)\n",
        "    in real-time during training.\n",
        "    \"\"\"\n",
        "    def __init__(self, epochs):\n",
        "        super().__init__()\n",
        "        self.epochs = epochs\n",
        "        self.epoch_history = []\n",
        "        self.history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': [], 'lr': []}\n",
        "        plt.ion() # Turn on interactive mode for live plotting\n",
        "\n",
        "        # Setup the plot figures and axes\n",
        "        self.fig, (self.ax1, self.ax2, self.ax3) = plt.subplots(3, 1, figsize=(10, 12))\n",
        "        self.fig.suptitle('Real-time Training Metrics', fontsize=16)\n",
        "\n",
        "        # Plot 1: Loss\n",
        "        self.line_loss, = self.ax1.plot([], [], 'r-', label='Loss')\n",
        "        self.line_val_loss, = self.ax1.plot([], [], 'b-', label='Val Loss')\n",
        "        self.ax1.set_ylabel('Loss')\n",
        "        self.ax1.legend()\n",
        "        self.ax1.grid(True)\n",
        "        self.ax1.set_xlim(0, epochs)\n",
        "        self.ax1.set_ylim(0, 5) # Initial reasonable y-limit for loss, adjust if needed\n",
        "\n",
        "        # Plot 2: Accuracy\n",
        "        self.line_acc, = self.ax2.plot([], [], 'r-', label='Accuracy')\n",
        "        self.line_val_acc, = self.ax2.plot([], [], 'b-', label='Val Accuracy')\n",
        "        self.ax2.set_ylabel('Accuracy')\n",
        "        self.ax2.legend()\n",
        "        self.ax2.grid(True)\n",
        "        self.ax2.set_xlim(0, epochs)\n",
        "        self.ax2.set_ylim(0, 1) # Accuracy is always 0-1\n",
        "\n",
        "        # Plot 3: Learning Rate\n",
        "        self.line_lr, = self.ax3.plot([], [], 'g-', label='Learning Rate')\n",
        "        self.ax3.set_xlabel('Epoch')\n",
        "        self.ax3.set_ylabel('Learning Rate')\n",
        "        self.ax3.legend()\n",
        "        self.ax3.grid(True)\n",
        "        self.ax3.set_xlim(0, epochs)\n",
        "        # Adjust y-limit for LR based on your optimizer's initial LR and reduction factor\n",
        "        self.ax3.set_ylim(1e-7, 1e-3)\n",
        "        self.ax3.set_yscale('log') # Log scale is often useful for LR plots\n",
        "\n",
        "        self.fig.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent suptitle overlap\n",
        "        self.fig.show()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        \"\"\"Updates the plots at the end of each epoch.\"\"\"\n",
        "        logs = logs or {}\n",
        "        self.epoch_history.append(epoch + 1)\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['val_loss'].append(logs.get('val_loss'))\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "        self.history['val_accuracy'].append(logs.get('val_accuracy'))\n",
        "        # Get current learning rate from the optimizer\n",
        "        self.history['lr'].append(self.model.optimizer.learning_rate.numpy())\n",
        "\n",
        "        # Update data for loss plot\n",
        "        self.line_loss.set_data(self.epoch_history, self.history['loss'])\n",
        "        self.line_val_loss.set_data(self.epoch_history, self.history['val_loss'])\n",
        "        self.ax1.relim() # Recalculate limits\n",
        "        self.ax1.autoscale_view() # Autoscale view\n",
        "\n",
        "        # Update data for accuracy plot\n",
        "        self.line_acc.set_data(self.epoch_history, self.history['accuracy'])\n",
        "        self.line_val_acc.set_data(self.epoch_history, self.history['val_accuracy'])\n",
        "        self.ax2.relim()\n",
        "        self.ax2.autoscale_view()\n",
        "\n",
        "        # Update data for learning rate plot\n",
        "        self.line_lr.set_data(self.epoch_history, self.history['lr'])\n",
        "        self.ax3.relim()\n",
        "        self.ax3.autoscale_view()\n",
        "\n",
        "        # Redraw the canvas and flush events to update the plot\n",
        "        self.fig.canvas.draw()\n",
        "        self.fig.canvas.flush_events()\n",
        "        plt.pause(0.01) # Small pause to allow plot to update\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        \"\"\"Turns off interactive mode and keeps the final plot open at the end of training.\"\"\"\n",
        "        plt.ioff() # Turn off interactive mode\n",
        "        plt.show() # Keep the final plot open\n",
        "\n",
        "# List of callbacks to be used during model training\n",
        "callbacks = [early_stopping, reduce_lr, LivePlotCallback(epochs=EPOCHS)]\n",
        "\n",
        "print(\"\\nTraining callbacks defined: EarlyStopping, ReduceLROnPlateau, and LivePlotCallback.\")\n",
        "print(\"These will be passed to your model.fit() method.\")"
      ],
      "metadata": {
        "id": "jX2BRscbgFnQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}